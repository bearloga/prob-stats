<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="5 Finite-State Markov Chains | Probability and Statistics" />
<meta property="og:type" content="book" />





<meta name="author" content="Bob Carpenter" />

<meta name="date" content="2019-01-01" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="5 Finite-State Markov Chains | Probability and Statistics">

<title>5 Finite-State Markov Chains | Probability and Statistics</title>

<link href="libs/tufte-css/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte.css" rel="stylesheet" />





</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="what-is-probability.html#what-is-probability">What is Probability?</a></li>
<li><a href="random-variables-and-event-probabilities.html#random-variables-and-event-probabilities"><span class="toc-section-number">1</span> Random Variables and Event Probabilities</a></li>
<li><a href="multiple-random-variables-and-probability-functions.html#multiple-random-variables-and-probability-functions"><span class="toc-section-number">2</span> Multiple Random Variables and Probability Functions</a></li>
<li><a href="expectations-and-variance.html#expectations-and-variance"><span class="toc-section-number">3</span> Expectations and Variance</a></li>
<li><a href="joint-marginal-and-conditional-probabilities.html#joint-marginal-and-conditional-probabilities"><span class="toc-section-number">4</span> Joint, Marginal, and Conditional Probabilities</a></li>
<li><a href="finite-state-markov-chains.html#finite-state-markov-chains"><span class="toc-section-number">5</span> Finite-State Markov Chains</a></li>
<li><a href="stationary-distributions-and-markov-chains.html#stationary-distributions-and-markov-chains"><span class="toc-section-number">6</span> Stationary Distributions and Markov Chains</a></li>
<li><a href="infinite-discrete-markov-chains.html#infinite-discrete-markov-chains"><span class="toc-section-number">7</span> Infinite Discrete Markov Chains</a></li>
<li><a href="continuous-random-variables.html#continuous-random-variables"><span class="toc-section-number">8</span> Continuous Random Variables</a></li>
<li><a href="continuous-distributions-and-densities.html#continuous-distributions-and-densities"><span class="toc-section-number">9</span> Continuous Distributions and Densities</a></li>
<li><a href="statistical-inference-and-inverse-problems.html#statistical-inference-and-inverse-problems"><span class="toc-section-number">10</span> Statistical Inference and Inverse Problems</a></li>
<li><a href="rejection-sampling.html#rejection-sampling"><span class="toc-section-number">11</span> Rejection Sampling</a></li>
<li><a href="posterior-predictive-inference.html#posterior-predictive-inference"><span class="toc-section-number">12</span> Posterior Predictive Inference</a></li>
<li><a href="pseudorandom-number-generators.html#pseudorandom-number-generators"><span class="toc-section-number">13</span> Pseudorandom Number Generators</a></li>
<li><a href="floating-point-arithmetic.html#floating-point-arithmetic"><span class="toc-section-number">14</span> Floating Point Arithmetic</a></li>
<li><a href="normal-distribution.html#normal-distribution"><span class="toc-section-number">15</span> Normal Distribution</a></li>
<li><a href="calibration-and-sharpness.html#calibration-and-sharpness"><span class="toc-section-number">16</span> Calibration and Sharpness</a></li>
<li><a href="regression-to-the-mean.html#regression-to-the-mean"><span class="toc-section-number">17</span> Regression to the Mean</a></li>
<li><a href="markov-chain-monte-carlo-methods.html#markov-chain-monte-carlo-methods"><span class="toc-section-number">18</span> Markov Chain Monte Carlo Methods</a></li>
<li><a href="random-walk-metropolis.html#random-walk-metropolis"><span class="toc-section-number">19</span> Random Walk Metropolis</a></li>
<li><a href="monitoring-approximate-convergence.html#monitoring-approximate-convergence"><span class="toc-section-number">20</span> Monitoring Approximate Convergence</a></li>
<li><a href="exponential-and-poisson-distributions.html#exponential-and-poisson-distributions"><span class="toc-section-number">21</span> Exponential and Poisson Distributions</a></li>
<li><a href="conjugate-priors.html#conjugate-priors"><span class="toc-section-number">22</span> Conjugate Priors</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="finite-state-markov-chains" class="section level1">
<h1><span class="header-section-number">5</span> Finite-State Markov Chains</h1>
<div id="random-processes" class="section level2">
<h2><span class="header-section-number">5.1</span> Random processes</h2>
<p>A finite sequence of random variables is said to be a random vector.
An infinite sequence</p>
<p><span class="math display">\[
Y = Y_1, Y_2, \ldots
\]</span></p>
<p>of random variables is said to be a <em>random process</em>.<label for="tufte-sn-87" class="margin-toggle sidenote-number">87</label><input type="checkbox" id="tufte-sn-87" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">87</span> We consider
only discrete random processes where the set of indexes is the
counting numbers <span class="math inline">\(1, 2, 3, \ldots\)</span>. Nevertheless, the set of indexes
is infinite, so much of the approach to finite vectors has to be
reworked.</span> A trivial example is a sequence of independent Bernoulli
trials in which each <span class="math inline">\(Y_t\)</span> is drawn independently according to <span class="math inline">\(Y_t \sim \mbox{bernoulli}(\theta)\)</span>. A sequence of independent Bernoulli
trials is called a <em>Bernoulli process.</em></p>
<p>In this chapter, we will restrict attention to processes <span class="math inline">\(Y\)</span> whose
elements take on values <span class="math inline">\(Y_t \in 0:N\)</span> or <span class="math inline">\(Y_t \in 1:N\)</span> for some fixed
<span class="math inline">\(N\)</span>.<label for="tufte-sn-88" class="margin-toggle sidenote-number">88</label><input type="checkbox" id="tufte-sn-88" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">88</span> The choice of starting at 0 or 1 is a convention that varies by
distribution. For example, Bernoulli and binomial variates may take
on value zero, but categorical values take on values in <span class="math inline">\(1:N\)</span>.</span> The
Bernoulli process is finite in this sense because each <span class="math inline">\(Y_t\)</span> takes on
boolean values, so that <span class="math inline">\(Y_t \in 0:1\)</span>.</p>
</div>
<div id="finite-state-markov-chains-1" class="section level2">
<h2><span class="header-section-number">5.2</span> Finite-State Markov chains</h2>
<p>A random process <span class="math inline">\(Y\)</span> is said to be a <em>Markov chain</em> if each element is
generated conditioned on only the previous element, so that</p>
<p><span class="math display">\[
p_{Y_{t + 1} \mid Y_1, \ldots, Y_t}(y_{t + 1} \mid y_1, \ldots, y_t)
\ = \
p_{Y_{t + 1} \mid Y_t}(y_{t + 1} \mid y_t)
\]</span></p>
<p>holds for all <span class="math inline">\(y_1, \ldots, y_{t + 1}\)</span>. In this chapter, we only
consider Markov chains in which the <span class="math inline">\(Y_t\)</span> are finite random variables
taking on values <span class="math inline">\(Y_t \in 0:N\)</span> or <span class="math inline">\(Y_t \in 1:N\)</span>, the range depending
on the type of variable.<label for="tufte-sn-89" class="margin-toggle sidenote-number">89</label><input type="checkbox" id="tufte-sn-89" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">89</span> We generalize in two later chapters, first
to Markov chains taking on countably infinite values and then to ones
with continous values.</span></p>
<p>The Bernoulli process discussed in the previous section is a trivial
example of a finite Markov chain. Each value is generated
independently, so that for all <span class="math inline">\(y_1, \ldots, y_{t+1}\)</span>, we have</p>
<p><span class="math display">\[
\begin{array}{rcl}
p_{Y_{t+1} \mid Y_1, \ldots, Y_t}(y_{t+1} \mid y_1, \ldots, y_t)
&amp; = &amp;
p_{Y_{t+1} \mid Y_t}(y_{t+1} \mid y_t)
\\[4pt]
= \mbox{bernoulli}(y_{t+1} \mid \theta).
\end{array}
\]</span></p>
</div>
<div id="fish-in-the-stream" class="section level2">
<h2><span class="header-section-number">5.3</span> Fish in the stream</h2>
<p>Suppose a person is ice fishing for perch and pike, and notes that if
they catch a perch, it is 95% likely that the next fish they catch is
a perch, whereas if they catch a pike, it is 20% likely the next fish
they catch is a pike.<label for="tufte-sn-90" class="margin-toggle sidenote-number">90</label><input type="checkbox" id="tufte-sn-90" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">90</span> This is a thinly reskinned version of the
classic exercise involving cars and trucks from Ross, S.M.,
2014. <em>Introduction to Probability Models.</em> Tenth edition. Academic
Press. Exercise 30, page 279.</span> We’ll treat the sequence of fish types
as a random process <span class="math inline">\(Y = Y_1, Y_2, \ldots\)</span> with values</p>
<p><span class="math display">\[
Y_t \ = \
\begin{cases}
1 &amp; \mbox{if fish $t$ is a pike, and}
\\[4pt]
2 &amp; \mbox{if fish $t$ is a perch.}
\end{cases}
\]</span></p>
<p>The sequence <span class="math inline">\(Y\)</span> forms a Markov chain with transition probabilities</p>
<p><span class="math display">\[
\begin{array}{rcl}
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 1] &amp; = &amp; 0.20
\\[4pt]
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 2] &amp; = &amp; 0.05
\end{array}
\]</span></p>
<p>The easiest way to visual a Markov chain with only a few states is as
a state transition diagram. In the case of the pike and perch, the
transition diagram is as follows.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-54"></span>
<p class="caption marginnote shownote">
Figure 5.1: State diagram for finite Markov chain generating sequences of fishes. The last fish observed determines the current state and the arrows indicate transition probabilities to the next fish observed.
</p>
<img src="_main_files/figure-html/unnamed-chunk-54-1.pdf" alt="State diagram for finite Markov chain generating sequences of fishes. The last fish observed determines the current state and the arrows indicate transition probabilities to the next fish observed." width="35%"  />
</div>
<p>Like all such transition graphs, the probabilities on the edges going
out of a node must sum to one.</p>
<p>Let’s simulate some fishing. The approach is to generate the type of
each fish in the sequence, then report the overall proportion of
pike.<label for="tufte-sn-91" class="margin-toggle sidenote-number">91</label><input type="checkbox" id="tufte-sn-91" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">91</span> With some sleight of hand here for compatiblity with Bernoulli
variates and to facilitate computing proportions, we have recoded
perch as having value 0 rather than 2.</span> We will start with a random
fish drawn according to <span class="math inline">\(\mbox{bernoulli(1/2)}\)</span>.</p>
<pre><code>y[1] = bernoulli_rng(0.5)
for (t in 2:T)
  y[t] = bernoulli_rng(y[t - 1] = 1 ? 0.2 : 0.05)
print &#39;simulated proportion of pike = &#39; sum(y) / M</code></pre>
<p>Now let’s assume the fish are really running, and run a few simulated
chains until <span class="math inline">\(T = 10\,000\)</span>.</p>
<pre><code>   simulated proportion of pike =   NA
   simulated proportion of pike =   NA
   simulated proportion of pike =   NA
   simulated proportion of pike =   NA
   simulated proportion of pike =   NA</code></pre>
<p>The proportion of pike is roughly 0.06.</p>
</div>
<div id="ehrenfests-urns" class="section level2">
<h2><span class="header-section-number">5.4</span> Ehrenfest’s Urns</h2>
<p>Suppose we have two urns, with a total of <span class="math inline">\(N\)</span> balls distributed
between them. At each time step, a ball is chosen uniformly at random
from among the balls in both urns and moved to the other urn.<label for="tufte-sn-92" class="margin-toggle sidenote-number">92</label><input type="checkbox" id="tufte-sn-92" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">92</span> This
model was originally introduced as an example of entropy and
equilibrium in P. Ehrenfest and T. Ehrenfest. 1906. Über eine Aufgabe
aus der Wahrscheinlichkeitsrechnung, die mit der kinetischen Deutung
der Entropievermehrung zusammenhängt.
<em>Mathematisch-Naturwissenschaftliche Blätter</em> No. 11 and 12.</span></p>
<p>The process defines a Markov chain <span class="math inline">\(Y\)</span> where transitions are governed
by</p>
<p><span class="math display">\[
p_{Y_{t+1} \mid Y_t}(y_{t+1} \mid y_t)
\ = \
\begin{cases}
\displaystyle \frac{y_t}{N}
&amp; \mbox{if } \ y_{t + 1} = y_t - 1, \ \mbox{and}
\\[6pt]
\displaystyle 1 - \frac{y_t}{N}
&amp; \mbox{if } \ y_{t + 1} = y_t + 1.
\end{cases}
\]</span></p>
<p>The transition probabilities make sure that the value of <span class="math inline">\(Y_t\)</span> remains
between 0 and <span class="math inline">\(N\)</span>. For example,</p>
<p><span class="math display">\[
\mbox{Pr}[Y_{t + 1} = 1 \mid Y_t = 0] = 1
\]</span></p>
<p>because <span class="math inline">\(1 - \frac{y_t}{N} = 1\)</span>. Similarly, if <span class="math inline">\(Y_t = N\)</span>, then
<span class="math inline">\(Y_{t+1} = N - 1\)</span>.</p>
<p>What happens to the distibution of <span class="math inline">\(Y_t\)</span> long term? It’s easy to
compute by simulation of a single long chain:<label for="tufte-sn-93" class="margin-toggle sidenote-number">93</label><input type="checkbox" id="tufte-sn-93" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">93</span> We’ve used a function
borrowed from R here called <code>table</code>, defined by <span class="math display">\[\mbox{table}(y, A,
B)[n] = \sum_{t=1}^T \mbox{I}[y_t = n]\]</span> for <span class="math inline">\(n \in A:B\)</span>. For example, if <span class="math display">\[y =
(0, 1, 2, 1, 1, 3, 2, 2, 1),\]</span> then <span class="math display">\[\mbox{table}(y, 0, 4) = (1, 4,
3, 1, 0),\]</span> because there is one 0, four 1s, three 2s, a single 3, and
no 4s among the values of <span class="math inline">\(y\)</span>.</span></p>
<pre><code>y[1] = floor(N / 2)
for (t in 2:T)
  z[t] = bernoulli_rng(y[t - 1] / N)
  y[t] = y[t - 1] + (z[t] ? -1 : +1)
p_Y_t_hat = table(y, 0, N) / T</code></pre>
<p>Let’s run that with <span class="math inline">\(N = 10\)</span> and <span class="math inline">\(T = 100\,000\)</span> and display the
results as a bar plot.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-56"></span>
<p class="caption marginnote shownote">
Figure 5.2: Long-term distribution of number of balls in the first urn of the Ehrenfest model in which <span class="math inline">\(N\)</span> balls are distributed between two urns, then at each time step, a ball is chosen uniformly at random move to the other urn. The simulation is based on total of <span class="math inline">\(T = 100\,000\)</span> steps with <span class="math inline">\(N = 10\)</span> balls, starting with 5 balls in the first urn. The points on the top of the bars are positioned at the mass defined by the binomial distribution, <span class="math inline">\(\mbox{binomial}(Y_t \mid 10, 0.5)\)</span>.
</p>
<img src="_main_files/figure-html/unnamed-chunk-56-1.png" alt="Long-term distribution of number of balls in the first urn of the Ehrenfest model in which $N$ balls are distributed between two urns, then at each time step, a ball is chosen uniformly at random move to the other urn.  The simulation is based on total of $T = 100\,000$ steps with $N = 10$ balls, starting with 5 balls in the first urn. The points on the top of the bars are positioned at the mass defined by the binomial distribution, $\mbox{binomial}(Y_t \mid 10, 0.5)$." width="90%"  />
</div>
<p>The distribution of <span class="math inline">\(Y_t\)</span> values is the binomial distribution, as
shown by the agreement between the points (the binomial probability
mass function) and the bars (the empirical proportion <span class="math inline">\(Y_t\)</span> spent in
each state).<label for="tufte-sn-94" class="margin-toggle sidenote-number">94</label><input type="checkbox" id="tufte-sn-94" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">94</span> In the Markov chain Monte Carlo chapter later in the
book, we will see how to construct a Markov chain whose long-term
frequency distribution matches any given target distribution.</span></p>
</div>
<div id="page-rank-and-the-random-surfer" class="section level2">
<h2><span class="header-section-number">5.5</span> Page Rank and the random surfer</h2>
<p>Pagerank,<label for="tufte-sn-95" class="margin-toggle sidenote-number">95</label><input type="checkbox" id="tufte-sn-95" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">95</span> Page, L., Brin, S., Motwani, R. and Winograd, T., 1999. The
PageRank citation ranking: Bringing order to the web. Stanford InfoLab
Technical Report. Section 2.5 Random Surfer Model.</span> the innovation
behind the original Google search engine ranking system, can be
modeled in terms of a random web surfer whose behavior determines a
Markov chain. The web is modeled as a set of pages, each of which has
a set of outgoing links to other pages. When viewing a particular
page, our random surfer chooses the next page to visit by</p>
<ul>
<li><p>if the current page has outgoing links, then with probability
<span class="math inline">\(\lambda\)</span>, choose the next page uniformly at random among the outgoing
links,</p></li>
<li><p>otherwise (with probability <span class="math inline">\(1 - \lambda\)</span>), choose the next page to
visit uniformly at random among all web pages.</p></li>
</ul>
<p>Translating this into the language of random variables, let <span class="math inline">\(Y = Y_1, Y_2, \ldots\)</span> be the sequence of web pages visited. Our goal now is to
define the transition function probabilistically so that we may
simulate the random surfer. Let <span class="math inline">\(L_i \subseteq 1:N\)</span> be the set of
outgoing links from page <span class="math inline">\(i\)</span>; each page may have any number of
outgoing links from 0 to <span class="math inline">\(N\)</span>.</p>
<p>The process <span class="math inline">\(Y\)</span> is most easily described in terms of an auxiliary
process <span class="math inline">\(Z = Z_1, Z_2, \ldots\)</span> where <span class="math inline">\(Z_t\)</span> represents</p>
<p>the decision whether to jump to a link from the current page. We
define <span class="math inline">\(Z\)</span> by setting <span class="math inline">\(Z_t = 0\)</span> if the page <span class="math inline">\(Y_t\)</span> has no
outgoing links, and otherwise setting</p>
<p><span class="math display">\[
Z_t \sim \mbox{bernoulli}(\lambda).
\]</span></p>
<p>If <span class="math inline">\(Z_t = 1\)</span>, we can generate <span class="math inline">\(Y_{t+1}\)</span> uniformly from the links
<span class="math inline">\(L_{Y_t}\)</span> from page <span class="math inline">\(Y_t\)</span>,</p>
<p><span class="math display">\[
Y_{t + 1} \sim \mbox{uniform}\left( L_{Y_t} \right).
\]</span></p>
<p>If <span class="math inline">\(Z_t = 0\)</span>, we simply choose a web page uniformly at random from
among all <span class="math inline">\(N\)</span> pages,</p>
<p><span class="math display">\[
Y_{t+1} \sim \mbox{uniform}(1:N).
\]</span></p>
<p>This sequence is easy to simulate with <code>L[n]</code> denoting the outgoing
links from page <code>n</code>. We start from a page <code>y[1]</code> chosen uniformly at
random among all the pages. Then we just simulate subsequent pages
according to the process described above.</p>
<pre><code>y[1] &lt;- uniform_rng(1:N)
for (t in 2:T)
  last_page = y[t - 1]
  out_links = L[last_page]
  z[t] &lt;- empty(out_links) ? 0 : bernoulli_rng(lambda)
  y[t] &lt;- uniform(z[t] ? out_links : (1:N))</code></pre>
<p>Suppose we have the following graph.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-57"></span>
<p class="caption marginnote shownote">
Figure 5.3: A simplified web. Each node represents a web page and each edge is a directed link from one page to another web page.
</p>
<img src="_main_files/figure-html/unnamed-chunk-57-1.pdf" alt="A simplified web.  Each node represents a web page and each edge is a directed link from one page to another web page." width="50%"  />
</div>
<p>We can simulate <span class="math inline">\(T = 100\,000\)</span> page visits using the algorithm shown
above and display the proportion of time spent on each page.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-58"></span>
<p class="caption marginnote shownote">
Figure 5.4: Proportion of time spent on each page by a random surfer taking <span class="math inline">\(T = 100\,000\)</span> page views starting from a random page with a web structured as in the previous diagram.
</p>
<img src="_main_files/figure-html/unnamed-chunk-58-1.png" alt="Proportion of time spent on each page by a random surfer taking $T = 100\,000$ page views starting from a random page with a web structured as in the previous diagram." width="90%"  />
</div>
<p>Page 1 is the most central hub. Pages 5, 6, 7, and 10 have no links
coming into them and can only be visited by random chance, so all
should have the same chance of being visited by the random surfer.
Pages 11 and 12 are symmetric, and indeed have the same probability.
There is a slight difference between the views of page 9 and 10 in
that it possible ot get to 9 from 7, but 10 is only visited by chance.</p>

</div>
</div>
<p style="text-align: center;">
<a href="joint-marginal-and-conditional-probabilities.html"><button class="btn btn-default">Previous</button></a>
<a href="stationary-distributions-and-markov-chains.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
