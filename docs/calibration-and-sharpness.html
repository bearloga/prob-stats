<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="16 Calibration and Sharpness | Probability and Statistics" />
<meta property="og:type" content="book" />





<meta name="author" content="Bob Carpenter" />

<meta name="date" content="2019-01-01" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="16 Calibration and Sharpness | Probability and Statistics">

<title>16 Calibration and Sharpness | Probability and Statistics</title>

<link href="libs/tufte-css/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css/tufte.css" rel="stylesheet" />





</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface">Preface</a></li>
<li><a href="what-is-probability.html#what-is-probability">What is Probability?</a></li>
<li><a href="random-variables-and-event-probabilities.html#random-variables-and-event-probabilities"><span class="toc-section-number">1</span> Random Variables and Event Probabilities</a></li>
<li><a href="multiple-random-variables-and-probability-functions.html#multiple-random-variables-and-probability-functions"><span class="toc-section-number">2</span> Multiple Random Variables and Probability Functions</a></li>
<li><a href="expectations-and-variance.html#expectations-and-variance"><span class="toc-section-number">3</span> Expectations and Variance</a></li>
<li><a href="joint-marginal-and-conditional-probabilities.html#joint-marginal-and-conditional-probabilities"><span class="toc-section-number">4</span> Joint, Marginal, and Conditional Probabilities</a></li>
<li><a href="finite-state-markov-chains.html#finite-state-markov-chains"><span class="toc-section-number">5</span> Finite-State Markov Chains</a></li>
<li><a href="stationary-distributions-and-markov-chains.html#stationary-distributions-and-markov-chains"><span class="toc-section-number">6</span> Stationary Distributions and Markov Chains</a></li>
<li><a href="infinite-discrete-markov-chains.html#infinite-discrete-markov-chains"><span class="toc-section-number">7</span> Infinite Discrete Markov Chains</a></li>
<li><a href="continuous-random-variables.html#continuous-random-variables"><span class="toc-section-number">8</span> Continuous Random Variables</a></li>
<li><a href="continuous-distributions-and-densities.html#continuous-distributions-and-densities"><span class="toc-section-number">9</span> Continuous Distributions and Densities</a></li>
<li><a href="statistical-inference-and-inverse-problems.html#statistical-inference-and-inverse-problems"><span class="toc-section-number">10</span> Statistical Inference and Inverse Problems</a></li>
<li><a href="rejection-sampling.html#rejection-sampling"><span class="toc-section-number">11</span> Rejection Sampling</a></li>
<li><a href="posterior-predictive-inference.html#posterior-predictive-inference"><span class="toc-section-number">12</span> Posterior Predictive Inference</a></li>
<li><a href="pseudorandom-number-generators.html#pseudorandom-number-generators"><span class="toc-section-number">13</span> Pseudorandom Number Generators</a></li>
<li><a href="floating-point-arithmetic.html#floating-point-arithmetic"><span class="toc-section-number">14</span> Floating Point Arithmetic</a></li>
<li><a href="normal-distribution.html#normal-distribution"><span class="toc-section-number">15</span> Normal Distribution</a></li>
<li><a href="calibration-and-sharpness.html#calibration-and-sharpness"><span class="toc-section-number">16</span> Calibration and Sharpness</a></li>
<li><a href="regression-to-the-mean.html#regression-to-the-mean"><span class="toc-section-number">17</span> Regression to the Mean</a></li>
<li><a href="markov-chain-monte-carlo-methods.html#markov-chain-monte-carlo-methods"><span class="toc-section-number">18</span> Markov Chain Monte Carlo Methods</a></li>
<li><a href="random-walk-metropolis.html#random-walk-metropolis"><span class="toc-section-number">19</span> Random Walk Metropolis</a></li>
<li><a href="monitoring-approximate-convergence.html#monitoring-approximate-convergence"><span class="toc-section-number">20</span> Monitoring Approximate Convergence</a></li>
<li><a href="exponential-and-poisson-distributions.html#exponential-and-poisson-distributions"><span class="toc-section-number">21</span> Exponential and Poisson Distributions</a></li>
<li><a href="conjugate-priors.html#conjugate-priors"><span class="toc-section-number">22</span> Conjugate Priors</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="calibration-and-sharpness" class="section level1">
<h1><span class="header-section-number">16</span> Calibration and Sharpness</h1>
<div id="forecasting-the-weather" class="section level2">
<h2><span class="header-section-number">16.1</span> Forecasting the weather</h2>
<p>Meteorologists make predictions about the weather every day. Some of
these forecasts are probabilistic. For example, such a forecast might
be an 80% chance of rain over the next 24 hours in some geographic
area such as Dayton, Ohio.<label for="tufte-sn-217" class="margin-toggle sidenote-number">217</label><input type="checkbox" id="tufte-sn-217" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">217</span> This is trickier to measure than it
sounds, but let’s suppose for now that we can reliably determine if it
rained in a given area within a given period of time.</span> We can’t tell
much about the meteorologist from a single forecast and single
outcome—if it rains, we have a bit more faith in the forecaster and
if it doesn’t, a bit less faith.</p>
<p>Suppose we have 100 days on which the meteorologist predicted an 80%
chance of rain. Let’s further suppose, for the sake of this thought
experiment, that the chance of rain is independent on those 100
days.<label for="tufte-sn-218" class="margin-toggle sidenote-number">218</label><input type="checkbox" id="tufte-sn-218" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">218</span> In reality, weather in neighboring regions is related, as is
weather hour to hour and day to day.</span> How many days do we expect to
be rainy? About 80. But we don’t expect that number to be exact,
because we are dealing in probabilities. If there really was an
independent 80% chance of rain on 100 days, we would expect the
distribution of rainy days to be <span class="math inline">\(\mbox{binomial}(100, 0.8)\)</span>.</p>
<p>Another forecast we consider is temperature. Let’s say we’re
forecasting the temperature at noon on February 1, 2019 on Bondi Beach
in Sydney. A probabilistic forecast of temperature might take the form
that there’s a 90% chance the high temperature will be between 20.1
and 24.8 degrees celsius. We can consider calibration of such a
forecast in terms of its event probabilities, just like the chance of
rain. That 90% forecast is still very broad. A <em>sharper</em> forecast is
one with a narrower interval, such as <span class="math inline">\((22.3, 23.4)\)</span>. Given two
calibrated forecasts, a sharper forecaster is preferable as it
provides more information. For binary events, like rain or not rain,
we’d prefer the probability forecasts to be as close to 0 or 1 as
possible.</p>
<p><strong>EXAMPLE OF HOW THIS IS POSSIBLE</strong></p>
</div>
<div id="calibration" class="section level2">
<h2><span class="header-section-number">16.2</span> Calibration</h2>
<p>With statistical models, forecasts take on the form of posterior
probabilty distributions conditioned on some observed data.</p>
<p>Given a prior distribution <span class="math inline">\(p(\theta)\)</span> and sampling function <span class="math inline">\(p(y \mid \theta)\)</span>, we observe data <span class="math inline">\(y\)</span> and calculate a posterior distribution
over the model’s parameters with density <span class="math inline">\(p(\theta \ mid y)\)</span>.
Although the posterior is a distribution, we calculate it by means of
a finite number of simulated values <span class="math inline">\(\theta^{(1)}, \ldots, \theta^{(M)}\)</span>.</p>
<p>A posterior distribution provides probability statements about the
parameters <span class="math inline">\(\theta\)</span> conditioned on observing data <span class="math inline">\(y\)</span>. For example,
they provide interval probalities, such as <span class="math inline">\(\mbox{Pr}[\theta &gt; 0.5 \mid y]\)</span> or <span class="math inline">\(\mbox{Pr}[0.21 &lt; \theta &lt; 0.32 \mid y]\)</span>.</p>
<p>We would like these event probabilities to be calibrated in the sense
that if <span class="math inline">\(\mbox{Pr}[\theta &gt; 0.5]\)</span>, then there is a 50% chance that
<span class="math inline">\(\theta\)</span> is greater than 0.5.</p>
<p>If our model has a prior
distribution with density <span class="math inline">\(p(\theta)\)</span> and a sampling distribution with
probability function <span class="math inline">\(p(y \mid \theta)\)</span>, then the posterior density is
<span class="math inline">\(p(\theta \mid y)\)</span>.</p>
<p>The posterior distributiondensity <span class="math inline">\(p(\theta \mid y)\)</span> given data <span class="math inline">\(y\)</span> and model
parameters <span class="math inline">\(\theta\)</span> provides predictions about the value of <span class="math inline">\(\theta\)</span></p>
<p>Inference provides posterior draws <span class="math inline">\(\theta^{(m)}\)</span> drawn according to the posterior density
Given some observed data <span class="math inline">\(y\)</span> and a model <span class="math inline">\(p(y \mid \theta) \times p(\theta)\)</span> with parameters <span class="math inline">\(\theta\)</span>, our inference</p>

</div>
</div>
<p style="text-align: center;">
<a href="normal-distribution.html"><button class="btn btn-default">Previous</button></a>
<a href="regression-to-the-mean.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
